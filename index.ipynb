{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaspard\n",
    "> Gaspard is a helper for Google's Gemini Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev import show_doc\n",
    "from fastcore.utils import *\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install gaspard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the [instructions](https://aistudio.google.com/app/apikey) to generate an API key, and set it as an evironment variable as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "export GEMINI_API_KEY=YOUR_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini's Python SDK will automatically be installed with Gaspard, if you don't already have it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaspard import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaspard provides models, which lists the models available in the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemini-1.5-pro-exp-0827',\n",
       " 'gemini-1.5-flash-exp-0827',\n",
       " 'gemini-1.5-pro',\n",
       " 'gemini-1.5-flash')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our examples we'll use `gemini-1.5-flash` since it's relatively faster and cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main interface to Gaspard is the `Chat` class which provides a stateful interface to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Faisal! ðŸ˜Š  What can I help you with today? \n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Nice to meet you, Faisal! ðŸ˜Š  What can I help you with today? \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 13\n",
       "- candidates_token_count: 17\n",
       "- total_token_count: 30\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Nice to meet you, Faisal! \\ud83d\\ude0a  What can I help you with today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 13,\n",
       "        \"candidates_token_count\": 17,\n",
       "        \"total_token_count\": 30\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
    "chat(\"I'm Faisal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Faisal. ðŸ˜Š \n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Your name is Faisal. ðŸ˜Š \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 40\n",
       "- candidates_token_count: 6\n",
       "- total_token_count: 46\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Your name is Faisal. \\ud83d\\ude0a \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 40,\n",
       "        \"candidates_token_count\": 6,\n",
       "        \"total_token_count\": 46\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(\"What's my name?\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, displaying the results of a call in a notebook shows just the message contents, with the other details hidden behind a collapsible section. Alternatively you can print the details:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Your name is Faisal. \\ud83d\\ude0a \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 40,\n",
      "        \"candidates_token_count\": 6,\n",
      "        \"total_token_count\": 46\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use stream=True to stream the results as soon as they arrive (although you will only see the gradual generation if you execute the notebook yourself, of course!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'parts': [{'text': \"I'm Faisal\"}]},\n",
       " {'role': 'model',\n",
       "  'parts': ['Nice to meet you, Faisal! ðŸ˜Š  What can I help you with today? \\n']},\n",
       " {'role': 'user', 'parts': [{'text': \"What's my name?\"}]},\n",
       " {'role': 'model', 'parts': ['Your name is Faisal. ðŸ˜Š \\n']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have a name. I'm a large language model, and I'm here to help you with information and tasks. ðŸ˜Š \n"
     ]
    }
   ],
   "source": [
    "for o in chat(\"What's your name?\", stream=True): print(o, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, welcome back to the land of the living Bard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool use lets the model use external tools.\n",
    "\n",
    "We use docments to make defining Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. As an example we'll write a simple function that adds numbers together, and will tell us when it's being called:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int=1 # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the model will say something like \"according to the sums tool the answer is\" -- generally we'd rather it just tells the user the answer, so we can use a system prompt to help with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \"Never mention what tools you use.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the model to add up some long numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is 604542+6458932?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use tools, pass a list of them to Chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model, sp=sp, tools=[sums])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we call that with our prompt, the model doesn't return the answer, but instead returns a `function_call` message, which means we have to call the named function (tool) with the provided parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "function_call {\n",
       "  name: \"sums\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"b\"\n",
       "      value {\n",
       "        number_value: 6458932\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"a\"\n",
       "      value {\n",
       "        number_value: 604542\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'function_call': {'name': 'sums', 'args': {'a': 604542.0, 'b': 6458932.0}}}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 76\n",
       "- candidates_token_count: 29\n",
       "- total_token_count: 105\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"sums\",\n",
       "                  \"args\": {\n",
       "                    \"a\": 604542.0,\n",
       "                    \"b\": 6458932.0\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 76,\n",
       "        \"candidates_token_count\": 29,\n",
       "        \"total_token_count\": 105\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(pr); r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaspard handles all that for us -- we just have to pass along the message, and it all happens automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'parts': [{'text': 'What is 604542+6458932?'}]},\n",
       " {'role': 'model',\n",
       "  'parts': [function_call {\n",
       "     name: \"sums\"\n",
       "     args {\n",
       "       fields {\n",
       "         key: \"b\"\n",
       "         value {\n",
       "           number_value: 6458932\n",
       "         }\n",
       "       }\n",
       "       fields {\n",
       "         key: \"a\"\n",
       "         value {\n",
       "           number_value: 604542\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   }]},\n",
       " {'role': 'user',\n",
       "  'parts': [name: \"sums\"\n",
       "   response {\n",
       "     fields {\n",
       "       key: \"result\"\n",
       "       value {\n",
       "         number_value: 7063474\n",
       "       }\n",
       "     }\n",
       "   }]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "7063474\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': '7063474'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 126\n",
       "- candidates_token_count: 7\n",
       "- total_token_count: 133\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"7063474\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 126,\n",
       "        \"candidates_token_count\": 7,\n",
       "        \"total_token_count\": 133\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the history to see what happens under the hood. Gaspard calls the tool with the appropriate variables returned by the `function_call` message from the model. The result of calling the function is then sent back to the model, which uses that to respond to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'model',\n",
       "  'parts': [function_call {\n",
       "     name: \"sums\"\n",
       "     args {\n",
       "       fields {\n",
       "         key: \"b\"\n",
       "         value {\n",
       "           number_value: 6458932\n",
       "         }\n",
       "       }\n",
       "       fields {\n",
       "         key: \"a\"\n",
       "         value {\n",
       "           number_value: 604542\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   }]},\n",
       " {'role': 'user',\n",
       "  'parts': [name: \"sums\"\n",
       "   response {\n",
       "     fields {\n",
       "       key: \"result\"\n",
       "       value {\n",
       "         number_value: 7063474\n",
       "       }\n",
       "     }\n",
       "   }]},\n",
       " {'role': 'model', 'parts': ['7063474']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how many tokens have been used at any time by checking the `use` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 202; Out: 36; Total: 238"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do everything needed to use tools in a single step, by using Chat.toolloop. This can even call multiple tools as needed solve a problem. For example, let's define a tool to handle multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mults(\n",
    "    a:int,  # First thing to multiply\n",
    "    b:int=1 # Second thing to multiply\n",
    ") -> int: # The product of the inputs\n",
    "    \"Multiplies a * b.\"\n",
    "    print(f\"Finding the product of {a} and {b}\")\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with a single call we can calculate `(a+b)*2` -- by passing `show_trace` we can see each response from the model in the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate (604542+6458932)*2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=sp, tools=[sums,mults])\n",
    "pr = f'Calculate ({a}+{b})*2'\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pchoice(r): print(r.parts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n",
      "function_call {\n",
      "  name: \"sums\"\n",
      "  args {\n",
      "    fields {\n",
      "      key: \"b\"\n",
      "      value {\n",
      "        number_value: 6458932\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      key: \"a\"\n",
      "      value {\n",
      "        number_value: 604542\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Finding the product of 7063474.0 and 2.0\n",
      "function_call {\n",
      "  name: \"mults\"\n",
      "  args {\n",
      "    fields {\n",
      "      key: \"b\"\n",
      "      value {\n",
      "        number_value: 2\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      key: \"a\"\n",
      "      value {\n",
      "        number_value: 7063474\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "text: \"The answer is 14126948. \\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = chat.toolloop(pr, trace_func=pchoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the trace above that the model correctly calls the sums function first to add the numbers inside the parenthesis and then calls the mults function to multiply the result of the summation by `2`. The response sent back to the user is the actual result after performing the chained tool calls, shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The answer is 14126948. \n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'The answer is 14126948. \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 226\n",
       "- candidates_token_count: 13\n",
       "- total_token_count: 239\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The answer is 14126948. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 226,\n",
       "        \"candidates_token_count\": 13,\n",
       "        \"total_token_count\": 239\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want the immediate result from a single tool, use `Client.structured`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Client(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int=1 # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7063474.0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.structured(\"What is 604542+6458932\", sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is particularly useful for getting back structured information, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class President(BasicRepr):\n",
    "    \"Information about a president of the United States\"\n",
    "    def __init__(self, \n",
    "                first:str, # first name\n",
    "                last:str, # last name\n",
    "                spouse:str, # name of spouse\n",
    "                years_in_office:str, # format: \"{start_year}-{end_year}\"\n",
    "                birthplace:str, # name of city\n",
    "                birth_year:int # year of birth, `0` if unknown\n",
    "        ):\n",
    "        assert re.match(r'\\d{4}-\\d{4}', years_in_office), \"Invalid format: `years_in_office`\"\n",
    "        store_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "President(first='Thomas', last='Jefferson', spouse='Martha Wayles Skelton', years_in_office='1801-1809', birthplace='Shadwell, Virginia', birth_year=1743.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.structured(\"Provide key information about the 3rd President of the United States\", President)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As everyone knows, when testing image APIs you have to use a cute puppy. But, that's boring, so here's a baby hippo instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fn = Path('samples/baby_hippo.jpg')\n",
    "display.Image(filename=img_fn, width=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `Chat` object as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gaspard, we can simply pass `Path` objects that repsent the path of the images. To pass multi-part messages, such as an image along with a prompt, we simply pass in a list of items. Note that Gaspard expects each item to be a text or a `Path` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading media..."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "A small hippopotamus is resting its head on a person's hand.\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"A small hippopotamus is resting its head on a person's hand.\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 268\n",
       "- candidates_token_count: 15\n",
       "- total_token_count: 283\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"A small hippopotamus is resting its head on a person's hand.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 268,\n",
       "        \"candidates_token_count\": 15,\n",
       "        \"total_token_count\": 283\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([img_fn, \"In brief, is happening in the photo?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, Gaspard uploads the image using Gemini's `File API` and passes a reference to the model. Gemini API will automatically infer the MIME type, and convert it appropriately. NOTE that the image is also included in input tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 268; Out: 15; Total: 283"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Gaspard supports creating a multi-stage chat with separate image and text prompts. For instance, you can pass just the image as the initial prompt (in which case the model will make some general comments about what it sees), and then follow up with questions in additional prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading media..."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This is a very cute photo of a baby hippopotamus. It looks like it's being petted by a human hand. The hippopotamus has a very sweet expression on its face and looks very happy to be getting attention. The photo is taken from a close up perspective, which makes the hippopotamus look even cuter.\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"This is a very cute photo of a baby hippopotamus. It looks like it's being petted by a human hand. The hippopotamus has a very sweet expression on its face and looks very happy to be getting attention. The photo is taken from a close up perspective, which makes the hippopotamus look even cuter.\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 259\n",
       "- candidates_token_count: 66\n",
       "- total_token_count: 325\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"This is a very cute photo of a baby hippopotamus. It looks like it's being petted by a human hand. The hippopotamus has a very sweet expression on its face and looks very happy to be getting attention. The photo is taken from a close up perspective, which makes the hippopotamus look even cuter.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 259,\n",
       "        \"candidates_token_count\": 66,\n",
       "        \"total_token_count\": 325\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model)\n",
    "chat(img_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The hippopotamus is facing **towards the right**. \n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'The hippopotamus is facing **towards the right**. \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 334\n",
       "- candidates_token_count: 10\n",
       "- total_token_count: 344\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The hippopotamus is facing **towards the right**. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 334,\n",
       "        \"candidates_token_count\": 10,\n",
       "        \"total_token_count\": 344\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('What direction is the hippo facing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The baby hippopotamus is a light greyish-brown color.  It's also a bit pink on its belly and around its eyes. \n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"The baby hippopotamus is a light greyish-brown color.  It's also a bit pink on its belly and around its eyes. \\n\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 353\n",
       "- candidates_token_count: 28\n",
       "- total_token_count: 381\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The baby hippopotamus is a light greyish-brown color.  It's also a bit pink on its belly and around its eyes. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 353,\n",
       "        \"candidates_token_count\": 28,\n",
       "        \"total_token_count\": 381\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('What color is it?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the image is passed in again for every input in the dialog, via the chat history, so the number of input tokens increases quickly with this kind of chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 946; Out: 104; Total: 1050"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond images, we can also pass in other kind of media to Gaspard, such as audio file, video files, documents, etc.\n",
    "\n",
    "For example, let's try to send a pdf file to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_fn = Path('samples/attention_is_all_you_need.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading media..."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This paper introduces the Transformer, a new neural network architecture for sequence transduction. It uses attention mechanisms to model dependencies between input and output, rather than recurrent or convolutional neural networks. The Transformer is significantly faster to train and achieves state-of-the-art results on machine translation tasks. The paper also shows that the Transformer generalizes well to other tasks, such as English constituency parsing.\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'This paper introduces the Transformer, a new neural network architecture for sequence transduction. It uses attention mechanisms to model dependencies between input and output, rather than recurrent or convolutional neural networks. The Transformer is significantly faster to train and achieves state-of-the-art results on machine translation tasks. The paper also shows that the Transformer generalizes well to other tasks, such as English constituency parsing.'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 14923\n",
       "- candidates_token_count: 77\n",
       "- total_token_count: 15000\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"This paper introduces the Transformer, a new neural network architecture for sequence transduction. It uses attention mechanisms to model dependencies between input and output, rather than recurrent or convolutional neural networks. The Transformer is significantly faster to train and achieves state-of-the-art results on machine translation tasks. The paper also shows that the Transformer generalizes well to other tasks, such as English constituency parsing.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 14923,\n",
       "        \"candidates_token_count\": 77,\n",
       "        \"total_token_count\": 15000\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([pdf_fn, \"In brief, what are the main ideas of this paper?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass in audio files in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_fn = Path('samples/attention_is_all_you_need.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = \"This is a podcast about the same paper. What important details from the paper are not in the podcast?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading media..."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The podcast doesn't mention several important aspects of the paper, including: \n",
       "\n",
       "* **Specific details about the architecture of the Transformer.** While the podcast discusses the core idea of attention mechanisms and how they differ from previous models, it doesn't explain the specific details of the Transformer's architecture, such as the number of layers, the dimension of the embeddings, or the specific type of attention mechanism used. \n",
       "* **Empirical results for other tasks.** The podcast focuses on machine translation results, but the paper also evaluates the Transformer's performance on English constituency parsing. \n",
       "* **Limitations and future directions.** The podcast mentions the authors' acknowledgement of the quadratic cost of attention for long sequences and their suggestion to explore restricted attention mechanisms. However, it doesn't delve deeper into the potential limitations of the Transformer and the authors' specific plans for future research. \n",
       "* **The significance of the Transformer for the field of natural language processing.** The podcast mentions the potential for faster training and better results across NLP tasks, but it doesn't elaborate on the broader impact of the Transformer on the field, such as its ability to handle different modalities and the shift from recurrent to attention-based models. \n",
       "* **Visualizations of attention.** The podcast doesn't mention the paper's inclusion of visualizations of the attention mechanism, which provide insights into how the model learns to capture syntactic and semantic relationships between words. \n",
       "\n",
       "Overall, the podcast provides a high-level overview of the paper, but it doesn't go into the depth of detail that the paper itself provides.\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"The podcast doesn't mention several important aspects of the paper, including: \\n\\n* **Specific details about the architecture of the Transformer.** While the podcast discusses the core idea of attention mechanisms and how they differ from previous models, it doesn't explain the specific details of the Transformer's architecture, such as the number of layers, the dimension of the embeddings, or the specific type of attention mechanism used. \\n* **Empirical results for other tasks.** The podcast focuses on machine translation results, but the paper also evaluates the Transformer's performance on English constituency parsing. \\n* **Limitations and future directions.** The podcast mentions the authors' acknowledgement of the quadratic cost of attention for long sequences and their suggestion to explore restricted attention mechanisms. However, it doesn't delve deeper into the potential limitations of the Transformer and the authors' specific plans for future research. \\n* **The significance of the Transformer for the field of natural language processing.** The podcast mentions the potential for faster training and better results across NLP tasks, but it doesn't elaborate on the broader impact of the Transformer on the field, such as its ability to handle different modalities and the shift from recurrent to attention-based models. \\n* **Visualizations of attention.** The podcast doesn't mention the paper's inclusion of visualizations of the attention mechanism, which provide insights into how the model learns to capture syntactic and semantic relationships between words. \\n\\nOverall, the podcast provides a high-level overview of the paper, but it doesn't go into the depth of detail that the paper itself provides.\\n\\n\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- avg_logprobs: 0.0\n",
       "- prompt_token_count: 22863\n",
       "- candidates_token_count: 320\n",
       "- total_token_count: 23183\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The podcast doesn't mention several important aspects of the paper, including: \\n\\n* **Specific details about the architecture of the Transformer.** While the podcast discusses the core idea of attention mechanisms and how they differ from previous models, it doesn't explain the specific details of the Transformer's architecture, such as the number of layers, the dimension of the embeddings, or the specific type of attention mechanism used. \\n* **Empirical results for other tasks.** The podcast focuses on machine translation results, but the paper also evaluates the Transformer's performance on English constituency parsing. \\n* **Limitations and future directions.** The podcast mentions the authors' acknowledgement of the quadratic cost of attention for long sequences and their suggestion to explore restricted attention mechanisms. However, it doesn't delve deeper into the potential limitations of the Transformer and the authors' specific plans for future research. \\n* **The significance of the Transformer for the field of natural language processing.** The podcast mentions the potential for faster training and better results across NLP tasks, but it doesn't elaborate on the broader impact of the Transformer on the field, such as its ability to handle different modalities and the shift from recurrent to attention-based models. \\n* **Visualizations of attention.** The podcast doesn't mention the paper's inclusion of visualizations of the attention mechanism, which provide insights into how the model learns to capture syntactic and semantic relationships between words. \\n\\nOverall, the podcast provides a high-level overview of the paper, but it doesn't go into the depth of detail that the paper itself provides.\\n\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 22863,\n",
       "        \"candidates_token_count\": 320,\n",
       "        \"total_token_count\": 23183\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([audio_fn, pr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be careful and monitor usage as the token usage rack up really fast! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 37786; Out: 397; Total: 38183"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use structured outputs with multi-modal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioMetadata(BasicRepr):\n",
    "    \"\"\"Class to hold metadata for audio files\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_speakers:int, # Number of speakers\n",
    "        topic:str, # Topic discussed\n",
    "        summary:str, # 100 word summary\n",
    "        transcript:list[str], # Transcript of the audio segmented by speaker\n",
    "    ): store_attr()\n",
    "pr = \"Extract the necessary information from the audio.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading media..."
     ]
    }
   ],
   "source": [
    "audio_md = cli.structured(mk_msgs([[audio_fn, pr]]), tools=[AudioMetadata])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers: 2.0\n",
      "Topic: Machine Learning and NLP\n",
      "Summary: This podcast dives into the paper \\\"Attention is All You Need\\\" by Vaswani et al., which introduces a new model architecture called the Transformer, based entirely on attention mechanisms, eliminating recurrence and convolutions used in previous models. This paper addresses limitations in previous models by proposing a new architecture which utilizes a stack of identical layers for both encoder and decoder. The authors highlight the model's capability to efficiently handle long-range dependencies in language, as well as its scalability and efficiency in training. The discussion also touches on the broader implications of this research, opening up new possibilities for sequence transduction tasks in the field of NLP.\n",
      "Transcript: 00:00 Welcome to our podcast where we dive\n",
      "-00:01 into groundbreaking research papers.\n",
      "-00:02 Today, we're discussing Attention is all\n",
      "-00:03 you need by Vaswani et al.\n",
      "-00:04 Joining us is an expert in machine\n",
      "-00:05 learning. Welcome.\n",
      "-00:06 Thanks for having me. I'm\n",
      "-00:07 excited to discuss this revolutionary\n",
      "-00:08 paper. Let's start with the core idea.\n",
      "-00:09 What's the main thrust of this research?\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of speakers: {audio_md.n_speakers}')\n",
    "print(f'Topic: {audio_md.topic}')\n",
    "print(f'Summary: {audio_md.summary}')\n",
    "transcript = '\\n-'.join(list(audio_md.transcript)[:10])\n",
    "print(f'Transcript: {transcript}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
